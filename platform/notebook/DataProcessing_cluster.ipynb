{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KEYSPACE = \"sparkassandra\"\n",
    "APP_NAME = KEYSPACE\n",
    "CASSANDRA_IP = \"cassandra_node\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBMIT_ARGS = \"--packages com.databricks:spark-csv_2.11:1.2.0,com.datastax.spark:spark-cassandra-connector_2.10:1.6.0-M1 pyspark-shell\"\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = SUBMIT_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure the driver and workers all use Python2\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Init Spark Conf\n",
    "conf = pyspark.SparkConf().setAppName(APP_NAME)\n",
    "conf.set(\"spark.cassandra.connection.host\",CASSANDRA_IP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init Spark Context\n",
    "sc = pyspark.SparkContext('spark://10.0.1.2:7077', conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Init Spark SQL Context\n",
    "sql_ctx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Flight Data from Cassandra (us_flights table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flights_df = sql_ctx.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"us_flights\", keyspace=KEYSPACE).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flights_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertColumn(df, name, newType) :\n",
    "    df_1 = df.withColumnRenamed(name, \"swap\")\n",
    "    df_1 = df_1.withColumn(name, df_1[\"swap\"].cast(newType)).drop(\"swap\")\n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flights_df = convertColumn(flights_df, \"dayofweek\", \"int\")\n",
    "flights_df = convertColumn(flights_df, \"arrdelay\", \"int\")\n",
    "flights_df = convertColumn(flights_df, \"depdelay\", \"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights_df.registerTempTable(\"flight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is the best day of week to fly to minimise delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SQL Request method\n",
    "#sql_ctx.sql(\"\"\"SELECT DayOfWeek as weekday, avg(ArrDelay) as avg_delay \n",
    "#                                FROM flight\n",
    "#                                GROUP BY DayOfWeek\n",
    "#                                ORDER BY avg_delay DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DataFrame syntax\n",
    "df_minimise_delays_weekday = (flights_df\n",
    "                              .select('dayofweek', 'arrdelay')\n",
    "                              .groupBy('dayofweek')\n",
    "                              .agg(F.avg('arrdelay').alias('AVG_DELAY_ARR')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def convert_day_of_week(val):\n",
    "    week   = ['Monday', \n",
    "              'Tuesday', \n",
    "              'Wednesday', \n",
    "              'Thursday',  \n",
    "              'Friday', \n",
    "              'Saturday',\n",
    "              'Sunday']\n",
    "    \n",
    "    return week[int(val)-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: it seems that calls to udf() must be after SparkContext() is called\n",
    "udf_convert_day_of_week = udf(convert_day_of_week, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_minimise_delays_weekday = df_minimise_delays_weekday.withColumn(\"DAY_OF_WEEK\", udf_convert_day_of_week(df_minimise_delays_weekday['dayofweek']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_minimise_delays_weekday[[\"DAY_OF_WEEK\", \"AVG_DELAY_ARR\"]].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "df_minimise_delays_weekday_pd = df_minimise_delays_weekday.toPandas()\n",
    "\n",
    "plt.figure(figsize=(30,8))\n",
    "ax = sns.barplot(x='DAY_OF_WEEK', y='AVG_DELAY_ARR', data=df_minimise_delays_weekday_pd)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x(), height+ 0.25, '%1.00f'%p.get_height())\n",
    "plt.title('When is the best time of day of time of year to fly to minimise delays?')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Average Delay')\n",
    "plt.legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is the best day of week of month to fly to minimise delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_minimise_delays_weekday_month = (flights_df\n",
    "                               .select('month', 'dayofweek', 'arrdelay')\n",
    "                               .groupBy('dayofweek').pivot('month').avg('arrdelay'))\n",
    "# Create Column DAY_OF_WEEK : convert int => string value\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumn(\"DAY_OF_WEEK\", udf_convert_day_of_week(df_minimise_delays_weekday.dayofweek))\n",
    "# Drop DayOfWeek (int value)\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.drop(\"dayofweek\")\n",
    "# Update column name : convert int month to str month\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"1\", \"January\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"2\", \"February\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"3\", \"March\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"4\", \"April\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"5\", \"May\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"6\", \"June\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"7\", \"July\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"8\", \"August\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"9\", \"September\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"10\", \"October\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"11\", \"November\")\n",
    "df_minimise_delays_weekday_month = df_minimise_delays_weekday_month.withColumnRenamed(\"12\", \"December\")\n",
    "df_minimise_delays_weekday_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas\n",
    "pd_minimise_delays_weekday_month = df_minimise_delays_weekday_month.toPandas()\n",
    "\n",
    "# Add Month column name to index columns\n",
    "pd_minimise_delays_weekday_month.columns.names = ['Month']\n",
    "\n",
    "# Update index values by DAY_OF_WEEK values & drop DAY_OF_WEEK columns\n",
    "pd_minimise_delays_weekday_month = pd_minimise_delays_weekday_month.rename(index=pd_minimise_delays_weekday_month.DAY_OF_WEEK).drop('DAY_OF_WEEK', axis=1)\n",
    "pd_minimise_delays_weekday_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Draw a heatmap \n",
    "grid_kws = {\"height_ratios\": (.9, .05), \"hspace\": 0.9}\n",
    "f, (ax, cbar_ax) = plt.subplots(2, figsize=(10, 5),gridspec_kw=grid_kws)\n",
    "sns.heatmap(pd_minimise_delays_weekday_month, ax=ax, linewidths=0.01, cmap=\"YlGnBu\", square=True, cbar_ax=cbar_ax, cbar_kws={\"orientation\": \"horizontal\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Airports Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airports_df = sql_ctx.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"airports\", keyspace=KEYSPACE).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is the best airport to fly to minimise delays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_minimise_delays_airport_dest = (flights_df\n",
    "                              .select('dest', 'arrdelay')\n",
    "                              .groupBy('dest')\n",
    "                              .agg(F.avg('arrdelay').alias('AVG_DELAY_ARR'))\n",
    "                              .sort(F.desc('AVG_DELAY_ARR')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge with airport data\n",
    "\n",
    "df_minimise_delays_airport_dest = (df_minimise_delays_airport_dest\n",
    "                 .join(airports_df, df_minimise_delays_airport_dest.dest == airports_df.iata, 'inner'))\n",
    "df_minimise_delays_airport_dest.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_minimise_delays_airport_dest = df_minimise_delays_airport_dest.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_minimise_delays_airport_dest.to_csv(\"pd_minimise_delays_airport_dest.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
